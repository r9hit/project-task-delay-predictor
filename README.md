# Task Delay Prediction Using Random Forest

## Project Overview

This project aims to predict task delays in a project management context using a **Random Forest Classifier**. The model utilizes multiple features (X1.1, X1.2, ..., X10.7) to predict the likelihood of a task delay, with multiple target variables (`Y1`, `Y2`, `Y3`, `Y4`) representing different aspects of project delay (e.g., time, cost, quality, etc.). This project demonstrates two approaches:

1. **Single-Target Prediction**: A model trained to predict a single target variable (`Y1`).
2. **Multi-Target Prediction**: A model that predicts multiple target variables (`Y1`, `Y2`, `Y3`, `Y4`) using `MultiOutputClassifier` to simulate real-world project management scenarios.

## Project Setup

### Prerequisites

To run this project, you need to have the following Python libraries installed:

- **Pandas**: For data handling and manipulation
- **NumPy**: For numerical operations
- **Scikit-learn**: For machine learning model building and evaluation
- **Matplotlib & Seaborn**: For data visualization
- **OpenPyXL**: For reading Excel files
- **Joblib**: For saving the trained model


## Dataset

The dataset used for this project is stored in an Excel file (`dataset.xlsx`). It contains features (X1.1, X1.2, ..., X10.7) and target variables (Y1, Y2, Y3, Y4), with each row representing a task in a project.

## Workflow

### 1. Single-Target Prediction (`delay_predictor_Y1.ipynb`)

This notebook demonstrates how to build a Random Forest Classifier model to predict a single target (Y1). The workflow for this notebook is as follows:

1. **Load the dataset**: The dataset is loaded from an Excel file and preprocessed.
2. **Feature Selection**: The features are selected from columns X1.1 to X10.7, and the target Y1 is isolated.
3. **Train-Test Split**: The data is split into training and testing sets (80-20 split).
4. **Random Forest Model**: A Random Forest classifier is trained on the data.
5. **Model Evaluation**: The model's performance is evaluated using metrics like accuracy, classification report, and confusion matrix.
6. **Feature Importance**: The importance of each feature is plotted to understand what drives task delays the most.

This approach helps demonstrate a detailed step-by-step workflow for training a classifier, visualizing the results, and analyzing the model.

### 2. Multi-Target Prediction (`delay_predictor_Y1_Y4.ipynb`)

In this notebook, we extend the previous model to handle multi-output classification using `MultiOutputClassifier`. The workflow is as follows:

1. **Load the dataset**: Similar to the single-target notebook, the dataset is loaded and preprocessed.
2. **Multi-output Target**: We select all four target variables (Y1, Y2, Y3, Y4) as output labels.
3. **MultiOutputClassifier**: A Random Forest model is applied to predict all four targets simultaneously.
4. **Model Evaluation**: The model's performance is evaluated for each target variable independently, and classification reports are generated.
5. **Feature Importance**: Feature importance is evaluated across all targets to understand the most influential features.

This approach showcases how to handle multi-target problems where predicting multiple related outcomes is essential in real-world project management scenarios.

## Insights

### 1. Feature Importance

By analyzing the feature importances generated by the Random Forest model, we can identify which features (e.g., task complexity, resource availability, dependency level) most influence the delay predictions. These insights can help project managers focus on key factors that contribute to delays.

### 2. Accuracy and Model Evaluation

The classification report and confusion matrix provide detailed insights into how well the model predicts task delays. High accuracy and low false positives/negatives indicate that the model is effective in predicting delays.

### 3. Scalability

While the single-target model is great for initial analysis, the multi-output model demonstrates scalability. Real-world projects often require predicting multiple outcomes (e.g., time delays, budget overruns), and this approach helps address such complexities.

## Feature Importance Insights from Model Y1

The plot below highlights which features contribute most to predicting delays:

| **Rank** | **Feature** | **Relative Importance** |
|----------|-------------|--------------------------|
| 1        | X8.1        | ~7.7%                   |
| 2        | X7.1        | ~6.1%                   |
| 3        | X10.3       | ~4.1%                   |
| 4        | X10.6       | ~3.9%                   |
| ...      | ...         | ...                     |

**X8.1**, **X7.1**, and **X10.3** are the most influential features for predicting **Y1**.  
These may correspond to dimensions like task urgency, resource availability, or team coordination (as defined in the data dictionary).


## Most Influential Features in Predicting Task Delay (Y1-Y4)

The following table lists the most influential features in predicting task delays across multiple targets (Y1-Y4):

| **Rank** | **Feature** | **Relative Insight** |
|----------|-------------|----------------------|
| 1        | X1.4        | This feature contributes the most. You might explore what X1.4 represents in your dataset â€” possibly a key performance metric or resource allocation factor. |
| 2        | X8.1        | Strong influence â€” might relate to team performance, task complexity, or cost estimation. |
| 3        | X8.3        | Closely follows X8.1 â€” could be correlated with X8.1 or represent another aspect of the same process. |
| 4â€“10     | X7.1, X7.7, X10.2, etc. | These are still significant but with slightly lower impact. May represent timelines, dependencies, or risks. |

You can observe a gradual drop in feature importance, indicating that some features contribute very little information to the model. These features could potentially be dropped or de-emphasized in simpler models.

### ðŸ§  Model Interpretation

- **X1.4**, **X8.1**, and **X8.3** are consistently important across all output targets (Y1-Y4). This suggests that these features are strong, general predictors of task delays across multiple dimensions.
- **Low-importance features** like X3.1, X1.7, and X4.1 might not add much to the predictions and could be candidates for **feature reduction** or **further analysis**.


## Why Random Forest?

1. **Handles Non-linear Relationships**: Random Forest is well-suited for capturing complex, non-linear relationships between the features and the target variables.
2. **Robust to Overfitting**: Random Forest can handle large datasets with many features without overfitting, which is crucial when dealing with noisy project data.
3. **Feature Importance**: The model provides an easy-to-understand ranking of feature importance, helping to interpret the results and understand which factors are most critical in predicting task delays.
4. **Multi-Output Capability**: The `MultiOutputClassifier` allows us to predict multiple related target variables at once, simulating real-world scenarios where multiple aspects of a task delay must be predicted simultaneously.
5. **No Scaling Required**: Random Forest does not require feature scaling, making it easier to work with raw, unprocessed data.

## Conclusion

This project demonstrates how machine learning, specifically Random Forest, can be applied to predict task delays in a project management context. By predicting multiple outputs (Y1 to Y4), this model aligns well with real-world needs, where project delays can have multiple dimensions (e.g., time, cost, resource allocation). The insights from this project can help project managers identify bottlenecks and take corrective actions proactively.


